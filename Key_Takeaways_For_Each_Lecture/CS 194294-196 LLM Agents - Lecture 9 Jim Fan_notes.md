# CS 194/294-196 (LLM Agents) - Lecture 9, Jim Fan

## 課程筆記

**A Tale of Two Kittens**
==========================

### Introduction

* Jim Fan: You're in the right room.
* This is the right title slide.
* "A Tale of Two Kittens."

### Inspiration Story

* In 1963, two scientists, Held and Hein, did an ingenious experiment.
* They put two newborn kittens in a device that looks like a merry-go-round.
* The active kitten can move freely, while the passive kitten is constrained to a basket.

### Experiment Results

* After a few days, the scientists test the kitten's visual system.
* Only the active kitten developed a healthy visual motor loop.
* The passive kitten was not able to respond to things like visual cliff or avoiding obstacles.

### Key Points

* **Embodiment and Active Agency**: These are what make us human.
* **Passive Kitten**: ChatGPT is an example of a very powerful passive kitten.
* **Human Babies**: We don't learn from Wikipedia, we play with objects and experiment.

### Project GR00T

* NVIDIA's goal to build the AI brain for humanoid robots.
* Jim Fan: I am leading the GEAR group, which stands for Generalists Embodied Agent Research.
* Project GR00T is announced at GTC, NVIDIA's biggest annual conference.

**人工智慧與機器人**
=====================

### 人工智慧在機器人中的應用

*   **第一個理由**: 我們需要一個能夠與人類一起工作的機器人。
*   **第二個理由**: 人形機器人的設計更為社會接受，易於預測行為。
*   **第三個理由**: 世界上的大部分設施和工具都設計給人類使用。

### 人工智慧在機器人中的發展

*   **第一個問題**: 為什麼現在是做這件事的好時候?
*   **答案**: 由於近年來出現了許多先進的人形機器人的硬件，成本也逐漸降低。
*   **例子**:
    *   Tesla Optimus
    *   Boston Dynamics e-Atlas
    *   Unitree G1

### 人工智慧在機器人中的未來發展

*   **預測**: 未來的人形機器人的成本將會繼續降低，甚至可能達到零成本。
*   **原因**:
    *   人形機器人所需的材料只佔車子的4%。
    *   產品成本的降低是由於材料成本的降低。

**Project GR00T**
================

### 什麼是 Project GR00T?

* **Generalist Robot 00 Technology**
	+ 是一種通用型機器人技術
	+ 可以應用於多個領域
* 目標是建立一個可以學習和改善的通用型機器人模型

### NLP 的成功故事

* **NLP** (自然語言處理) 是目前最成功的 AI 領域之一
* **ChatGPT** 的出現，證明了通用型機器人的可能性
* 通用型機器人可以通過提示和調整來專門化

### robotics 的挑戰

* 目前的機器人系統大多是特殊化的
* 需要特定的硬件和算法
* 不一定涉及學習或機器學習

### Project GR00T 的目標

* 模仿 NLP 的成功故事，建立一個通用型機器人模型
* 透過提示和調整來專門化
* 建立強大的特殊化機器人系統

### 三個核心原則

#### 1. **Data Pyramid Principle**

* 資料的層級結構
* 由基礎資料到高階資料
* 這可以幫助建立一個穩定的和可靠的模型

#### 2. **The Matrix Principle**

* 機器人的知識結構
* 由基礎知識到高階知識
* 這可以幫助機器人學習和改善

#### 3. **Foundation Agent Principle**

* 基礎代理原則
* 建立一個強大的基礎模型
* 透過提示和調整來專門化

### 結論

* Project GR00T 的目標是建立一個通用型機器人模型
* 這可以幫助建立強大的特殊化機器人系統
* 三個核心原則是建立這種模型的關鍵

**今日內容**
================

### **資料金字塔**

*   **資料金字塔**: 是一個描述資料量和質量的概念。
*   資料金字塔的頂端是高品質、豐富的資料。

### **莫拉維茨悖論**

*   **莫拉維茨悖論**: 說明一些對人類容易的事情，對機器來說卻很困難。
*   這個悖論解釋了為什麼 NLP 能夠快速發展，但仍然沒有出現一般性的機器人。

### **資料收集**

*   **實際機器人資料**: 是最重要的資料源頭。
*   由於物理限制，實際機器人資料的收集速度有限。

### **Apple Vision Pro**

*   **Apple Vision Pro**: 是一種使用 AR 技術的眼鏡裝置。
*   這個技術可以用來收集實際機器人資料，並且提供一個直觀的介面。

### **Omniverse Cloud**

*   **Omniverse Cloud**: 是 NVIDIA 的雲端平台，允許使用者在任何地方、任何時間都能夠操作虛擬機器人。
*   這個平台可以與任何 XR 裝置連接，提供一個直觀的介面。

### **資料收集系統**

*   **資料收集系統**: 是一個使用 Apple Vision Pro 和 Omniverse Cloud 的系統，用於收集實際機器人資料。
*   這個系統能夠提供一個直觀的介面，並且允許使用者在任何地方、任何時間都能夠操作虛擬機器人。

**Robotics and AI**
====================

### **Data Collection**

*   **Humanoid Robot**: 有五個手指，類似於人類的手。
*   **Training**: 不需要太多的訓練。
*   **Data Collection**: 可以在 10 分鐘內收集數據。

### **Simulation**

*   **NVIDIA Isaac Lab**: 使用 GPU 進行物理模擬。
*   **Simulation Speed**: 可以達到 10,000 倍於實際時間的速度。
*   **Break Physical Limit**: 超過 24 小時的限制。

### **Omniverse Platform**

*   **Real-time Rendering**: 使用硬件加速的光線追蹤技術進行實時渲染。
*   **Complex Worlds**: 可以創建複雜的世界，並且具有驚人的細節。
*   **Computer Vision Models**: 可以使用模擬來訓練電腦視覺模型。

### **Key Takeaways**

*   **Data Hungry**: 基礎模型需要大量數據。
*   **Simulation**: 模擬可以幫助超過實際時間的限制。

**Simulation**
================

### Segmentation and Perception Model

*   **每個分割**: 在模擬中使用遮罩。
*   **感知模型**: 利用遮罩建立機器人感知模型。

### Data Collection

*   **模擬和實際資料**: 收集模擬和實際機器人資料。
*   **網路資料**: 收集網路上的資料，包括文本和視頻。
*   **物理常識**: 機器人需要從大量視頻中學習物理常識。

### Data Scale

*   **大規模資料**: 每天收集的資料量達到 exabytes 以上。
*   **模擬資料**: 每個 GPU 每天收集的模擬資料量約為 terabytes。

### Matrix Principle

*   **建構機器人學習**: 考慮如何建立機器人的學習模型。
*   **兩個問題**:
    *   **是否我們生活在模擬中?**
    *   **如果是，則該如何應對?**

### Simulation and Robotics

*   **未來的機器人學習**: 未來的機器人將主要生活在模擬環境中。
*   **高品質 token**: 通過模擬收集大量高品質 token。
*   **24 小時限制**: 模擬可以突破每天 24 小時的限制。

### Simulation and AI

*   **模擬 vs 解決問題**: 模擬一個問題比解決它更容易。
*   **AlphaGo 和 Minecraft**: AlphaGo 和 Minecraft 的例子，展示了模擬的優勢。

**Simulation and AI**
=====================

### 1. Simulation in Minecraft
---------------------------

*   **Turing completeness**: Minecraft is Turing complete, meaning it can simulate any algorithm.
*   **CPU circuit simulation**: Someone built a functioning CPU circuit in Minecraft.

### 2. MineDojo Project
----------------------

*   **Framework for training AI**: MineDojo is a framework for training generally capable agents in Minecraft.
*   **API for AI simulator**: It provides a simulator as an API for AI and lots of data from the internet.
*   **Website**: Check out MineDojo.org.

### 3. Simulation and Data Generation
--------------------------------------

*   **Simulation fascinates me**: Simulating a world is easier than doing anything interesting in it.
*   **Data generation methods**:
    *   **Self-generating data**: Generating data within the simulation.
    *   **Multiply data**: Using real-world data to train AI.

### 4. Learning Paradigms
------------------------

*   **Reinforcement learning**: Training AI with a reward function to maximize desired behavior.
*   **Imitation learning**: Training AI by imitating human behavior.

### 5. Reinforcement Learning
-----------------------------

*   **Reward function**: A function that tells the AI what behavior is desired or not.
*   **Trial and error**: The AI does trial and error to maximize the reward.
*   **Example**: Pavlov's dog conditioning.

### 6. Whole Body Control
-------------------------

*   **Neural whole body control**: Using reinforcement learning for humanoid robots.
*   **Whole body local manipulation**: Manipulating objects while standing in balance.
*   **Examples**:
    *   Tesla Optimus walking.
    *   Apple Vision Pro tabletop manipulation.
    *   Boston Dynamics robot manipulating objects.

**HOVER Neural Network**
==========================

### **概述**

*   HOVER是一個神經網絡，用於控制人形機器人的運動和操控。
*   神經網絡能夠學習如何協調機器人的各個部分，例如手臂和腿部，以支持行走和操作。

### **控制模式**

*   **Kinematic Position Tracking**
    *   跟蹤機器人各個關節的位置。
*   **Local Joint Angle**
    *   跟蹤機器人各個關節之間的角度。
*   **Route Tracking**
    *   計劃和跟蹤機器人的運動路徑。

### **控制接口**

*   **Apple Vision Pro**
    *   使用頭部和手部姿勢追蹤來控制機器人。
*   **RGB Camera**
    *   使用計算視覺模型來識別人體姿勢，控制機器人。
*   **Exoskeleton**
    *   使用外骨骼來精確跟蹤機器人的運動。
*   **Joysticks or Game Controller**
    *   使用遊戲手柄或方向盤來控制機器人。

### **訓練模型**

*   **Simulation**
    *   在模擬環境中傳入控制模式和特定資訊，以訓練神經網絡。
*   **Privileged Information**
    *   在模擬環境中可用，但在實際世界中不可用。

**Act Location and Velocity**
=====================================

### 重點概念

*   **Privileged Information**: 在真實機器人中不可得的資訊
*   **Reinforcement Learning**: 使用獎勵機制來訓練政策
*   **Supervised Learning**: 使用監督式學習來訓練政策
*   **HOVER**: 一種能夠控制機器人的政策

### 重點概念列表

#### 1. **Privileged Information**

*   每個關節、每個原子都有獨特的資訊
*   在真實機器人中不可得

#### 2. **Reinforcement Learning**

*   使用獎勵機制來訓練政策
*   可以得到一個oracle policy控制機器人

#### 3. **Supervised Learning**

*   使用監督式學習來訓練政策
*   適合在較困難的問題上使用

#### 4. **HOVER**

*   一種能夠控制機器人的政策
*   可以控制頭部、身體、路徑速度等多個參數

### 重點概念分組

#### 1. **訓練 HOVER 政策**

*   使用兩階段的過程：首先使用監督式學習，然後使用強化學習
*   這樣可以避免在強化學習中出現不穩定的問題

#### 2. **HOVER 的應用**

*   可以控制多種機器人和環境
*   可以訓練多種政策，例如跟隨姿勢、行走等

**RoboCasa**
================

### 什麼是 RoboCasa?

*   **RoboCasa** 是一個生成式模擬框架，使用不同 AI 模型來生成物件、任務、材質和廚房佈局。
*   它可以創造多達 100,000 個不同的廚房。

### RoboCasa 的功能

*   **資料增強**: 使用 RoboCasa，可以將一個真實世界的示範重播並乘以 n 倍，生成更多的示範。
*   **模擬**: RoboCasa 可以使用 AI 模型來生成物件、任務、材質和廚房佈局。

### RoboCasa 的應用

*   **訓練模型**: 使用真實世界的資料和 RoboCasa 生成的模擬資料，可以訓練更好的視覺模型。
*   **多樣性**: RoboCasa 可以創造多種不同的廚房佈局和任務，增加模型的多樣性。

### 相關技術

*   **Stable Diffusion**: 一個 AI 模型，用於生成材質。
*   **USD (Universal Scene Description)**: 了一種描述場景的程式語言。
*   **ChatUSD**: 一個工具，用於 fine-tuning LLM 來生成 USD 格式的場景佈局。
*   **GPT-4 和 Claude-3.5**: 兩個 LLM，用於生成任務代碼。

**RoboCasa**
================

### **變異演算法**

*   **MimicGen**: 一個通用框架，能夠應用於多種任務
*   **RoboCasa**: 一種視覺增強技術
*   **Omniverse render**: 人類模擬器

### **變異演算法的優點**

*   能夠生成大量成功的運動軌跡
*   可以應用於多種任務，包括人形和機器人操作
*   能夠節省時間和資源，不需要人類進行反覆的演示

### **RoboCasa的功能**

*   能夠增強視覺效果
*   能夠變異運動軌跡和物體配置
*   能夠生成新的運動軌跡和物體配置

### **MimicGen的優點**

*   能夠節省時間和資源，不需要人類進行反覆的演示
*   可以應用於多種任務，包括人形和機器人操作
*   能夠生成大量成功的運動軌跡

**DexMimicGen**
================

### 重要概念

*   **MimicGen**: 一個用於生成大量資料的工具
*   **Bimanual Task**: 需要兩手協調完成的任務
*   **Coordination Subtask**: 需要兩手精確協調完成的任務
*   **Sequential Task**: 需要先完成某些前置任務才能進行下一步的任務

### DexMimicGen 的應用

#### 生成大量資料

*   使用 MimicGen 可以快速生成大量相關資料
*   這些資料可以幫助訓練機器學習模型

#### 適用於不同任務

*   **單手任務**: 如拿取物品等簡單任務
*   **雙手任務**: 如抬起物品、放置物品等需要兩手協調完成的任務
*   **協調任務**: 需要兩手精確協調完成的任務
*   **序列任務**: 需要先完成某些前置任務才能進行下一步的任務

#### 適用於不同機器人設定

*   **雙手設定**: 如抬起物品、放置物品等需要兩手協調完成的任務
*   **雙爪設定**: 如抓取物品等簡單任務
*   **人形設定**: 如做咖啡、分類垃圾等複雜任務

**MimicGen**
================

### 概念

* **Dexterous manipulation**: 手眼協調的操作
* **Diffusion policy**: 將資料從一種形式轉換為另一種形式的策略

### 結果

* 可以訓練政策
* 可以研究不同神經網路架構之間的差異
* 可以顯示在更困難的任務中，MimicGen的效率會提高

### 流程

1. 人類收集數據
2. 使用AI生成更多資料
3. 進行Real2Sim轉換（將真實世界的軌跡轉換為模擬世界）
4. 在模擬世界中運行DexMimicGen
5. 將結果回歸到真實世界

### 結果

* 可以顯示在真實世界中，效率會提高
* 可以節省人力

### 基礎原則

* **Foundation agent principle**: 建立基礎模型的原則
* 可以用於建構GR00T模型

### 三個維度

* **Embodiment**: 身體的能力
* **Skill**: 技能的數量
* **Reality**: 實際世界的能力

**Embodiments**
================

### What I mean by embodiments

*   **MetaMorph**: A proof of concept work that trained a single neural network to control thousands of different robots.
*   **Kinematic Tree**: A graph representation of a robot's joints and body structure.

### Key Concepts
-----------------

#### 1. **Robot Control**

*   Can we have a single neural network that can control all types of robots?
*   Yes, with MetaMorph, we can train a single neural network to control multiple robots.

#### 2. **Neural Network Architecture**

*   **Screaming Transformers**: A sequence model that maps robot descriptions to actions.
*   **MetaMorph Transformer**: Trains the screaming transformers to map sequences to actions directly.

#### 3. **Robot Training**

*   We train robots on various tasks, such as:
    *   Flat terrain
    *   Walking
    *   Complex terrains
    *   Avoiding obstacles

#### 4. **MetaMorph 2.0**

*   Goal: Train a single model to control all humanoid robot bodies.
*   Challenges:
    *   Different robot bodies
    *   Number of skills a robot agent can do

#### 5. **MimicGen and Robot Dexterity**

*   MimicGen allows robots to master more skills.
*   We train an agent that achieves superhuman-level robot dexterity.

### Takeaways
--------------

*   A single neural network can control multiple robots.
*   MetaMorph 2.0 aims to train a single model for all humanoid robot bodies.
*   MimicGen enables robots to master more skills, and we're working on automating this process.

**AI 的能力**
================

### **強大的工具**

*   AI 可以幫助我們克服技能不足。
*   但是我們是個不夠好的人類。

### **複雜的技能**

*   學習這項技能非常困難。
*   我們不知道如何指定獎勵函數。

### **獎勵函數**

*   奖励函数是一段 Python 代碼。
*   Isaac Lab 模擬器中的機器人模擬都是用 Python API 寫的。

### **使用 ChatGPT**

*   我們可以讓 ChatGPT 做繁瑣工作。
*   我們給 LLM 一個提示，請它找出一個能使 Shadow Hand 做筆記轉動的獎勵函數。

### **結果**

*   GPT-4 或其他前沿模型可以正確實現獎勵函數。
*   這是非常令人驚訝的，因為這些獎勵函數需要由訓練過的機器人家來寫。

### **迭代式改進**

*   我們使用 LLM 編輯代碼。
*   如果我們重複這個過程幾次，我們就能看到 Eureka 逐漸變得超越專家的獎勵函數。

**Eureka**
================

### 什麼是 Eureka?

*   **Eureka**: 一個 AI 模型，用於學習和執行複雜任務。
*   **Eureka Loop**: 一個迴圈，包含 GPT、Reward Function 和 Domain Randomization。

### Eureka 的特點

*   **多軸控制**: Eureka 可以在不同軸上控制任務的執行。
*   **自適應**: Eureka 可以根據任務的需求進行調整和改進。

### Domain Randomization
-------------------------

### 什麼是 Domain Randomization?

*   **Domain Randomization**: 一種技術，用於模擬實際世界中的物理參數，例如重力、摩擦等。
*   **DR**: Domain Randomization 的簡稱。

### DrEureka
-------------

### 什麼是 DrEureka?

*   **DrEureka**: 一個基於 Eureka 的模型，用於在實際世界中執行任務。
*   **DrEureka Loop**: 一個迴圈，包含 GPT、Reward Function 和 Domain Randomization。

### DrEureka 的特點

*   **自適應**: DrEureka 可以根據任務的需求進行調整和改進。
*   **多軸控制**: DrEureka 可以在不同軸上控制任務的執行。

**Eureka**
================

### 什么是 Eureka?

*   **超级 AI**: 能够在不需要人工调整的情况下在真实世界中实现零 shot 的能力。
*   **双循环系统**: 包括一个外循环进行推理和一个内循环进行模型控制。

### DrEureka

*   **升级版的 Eureka**: 能够写出奖励函数并配置 Sim2Real 以及能够在真实世界中实现零 shot 的能力。
*   **超级狗级别的智能**: 能够让机器狗在真实世界中进行复杂动作。

### 未来发展

*   **Eureka++**: 能够写出新任务、新模拟和新训练算法。
*   **实现 Eureka++ 的目标**: 能够让团队在一周内休假并仍然能够报告更新。

**實現人工智慧**
================

### 人工智慧的訓練方法

*   **ChatGPT**: 是一種序列模型，能夠輸入文本並產生文本，無論是程式碼寫作還是詩歌、摘要或推理都行。
*   **GR00T模型**: 類似於ChatGPT，但它的輸入是實體控制和自然語言指令，輸出是行動。

### 訓練方法

*   **資料量**: 需要大量的網路文本資料來訓練
*   **計算平台**: 需要一個適合的人工智慧訓練的計算平台

### 計算平台

*   **OVX (Graphics Computer)**: 生成令牌（token）
*   **DGX系統 (H100, H800s)**: 學習令牌
*   **AGX系統 (Jetson系列芯片)**: 部署令牌

### 軟體orchestration framework

*   **OSMO**: 用於調度異質計算工作負載的軟體框架

### 結論

*   人工智慧訓練需要大量資料和適合的人工智慧訓練的計算平台
*   計算平台包括OVX、DGX系統和AGX系統
*   軟體orchestration framework OSMO用於調度工作負載

**重要概念**
* **AGI (Artificial General Intelligence)**
* **GR00T**
* **Embodied AI**

**議程提要**
### 1. 全面就業市場的自動化
#### *使用一般性機器人基礎模型*
#### *將整個勞動市場轉變為$0 trillion業務*

### 2. AGI 的實現
#### *需要身體化*
#### *GR00T 將是未來關鍵技術*

### 3. 未來展望
#### *我們將建造活躍的貓咪*
#### *身體化 AI 是我們的目標*
#### *請加入我們的旅程*

---
## 參考資料
- 原始影片：[CS 194/294-196 (LLM Agents) - Lecture 9, Jim Fan](https://youtube.com/watch?v=Qhxr0uVT2zs)
