# CS 194/294-196 (LLM Agents) - Lecture 4, Burak Gokturk

## 課程筆記

**企業趨勢**
================

### 趨勢概述

*   **市場變化**:企業正在改變其對於人工智慧的看法和應用。
*   **深度學習**:在過去,企業可能會選擇使用傳統的機器學習模型,如支持向量機器(SVM)或決策樹。但是,隨著深度學習技術的進步,企業開始轉向使用神經網路。

### 神經網路的改變

*   **架構**:神經網路的架構設計使其更容易實現和優化。
*   **訓練集**:需要大量數據來並行化訓練過程。
*   **訓練時間**:隨著模型大小的增加,訓練時間也會大幅增加。

### 相關概念

*   **深度學習**:使用多層神經網路進行機器學習。
*   **並行化**:利用多核處理器或GPU來加速計算。
*   **數據集**:大量數據的集合,用於訓練模型。

### 重要提示

*   **企業應用**:企業正在轉向使用深度學習技術,以改善業務運作和決策。
*   **研究方向**:對於那些想進一步研究或開發深度學習技術的人,這是一個值得關注的領域。

**我的擔憂**
================

### 學習速度慢
-----------------

* 我們的學習速度似乎不夠快。
* 每 42 秒，我都在改變一些東西，然後觀察結果。

### 支持向量機 (SVM)
----------------------

* 過去大家都使用 SVM。
* 如果你改變這個參數，這樣的事情會發生。
* 如果你改變那個參數，這樣的另一件事情會發生。

### 大規模語言模型
-------------------

* 作為研究人員，我們需要快速地學習和改進。
* 我們需要能夠在短時間內得到結果。

### 效果慢
------------

* 我們的學習速度比過去慢了很多。
* 我們不確定什麼樣的事情會發生。

### 資料集
-------------

* 我們需要大量的資料來訓練模型。
* 我們可以使用遮罩技術來創建訓練資料。

### 過去的成就
----------------

* ChatGPT 的推出使我們意識到 AI 的實際能力。
* 公司內部的工具已經展示了 ChatGPT 的類似功能。

**AI 進展**
================

### **背景**

*   Brave move: 改變了全球的思維方式
*   AI 問題: 有許多改善, 特別是在最近十年中

### **進展**

#### **圖像識別**

*   ImageNet: 2011 年開始, accuracy rate 達到 50%
*   2022 年已經達到 91% 的 accuracy rate
*   大型模型的使用使得進展更快

#### **語言辨識**

*   2016 年: 13% 的 accuracy rate
*   2021 年: 2.5% 的 accuracy rate
*   現在已經有了顯著的改善

### **技術進步**

#### **神經網路**

*   轉換或結構化
*   有許多進展在演算法上

#### **訓練集生成**

*   Next token prediction: 產生大量的訓練集
*   運用句子和關鍵字來生成新的句子

**09:12] And I don't need to tell you**
### 因為你已經嘗試過這些事了

#### 主要概念：

* **_agents_**：一個過載的術語
* **_expert responses_**：專家回應
* **_supervised fine-tuning_**：監督式微調
* **_reinforcement learning from human feedback_**：基於人類反饋的強化學習

### 主要方法：

#### 1. 使用監督式微調

* 需要大量專家回應
* 需要找到專家並花時間在他們身上

#### 2. 使用基於人類反饋的強化學習

* 可以使用多個選擇來獲得人類反饋
* 人類可以快速給出「thumbs up」或「thumbs down」
* 這比提供專家回應更快

### 其他方法：

#### 1. 使用 **_Gemini_** 項目

* 是一個公開的資料集
* 可以使用來訓練大型語言模型
* 有能力提供大量上下文

#### 2. 搜索算法

* 是生活中的基本功能
* 大型語言模型也需要搜索算法才能工作良好

**Traditional Search Algorithms**
=====================================

*   **不能被替代**
    *   [12:32] algorithms, traditional search algorithms,
        [12:34] either keyword matching, or embeddings matching,
        [12:37] or deep retrieval techniques will not
        [12:39] be able to replace
        essentially traditional search
        [12:43] algorithms in future.
    *   [12:45] So I think that's something
        because it's a food for thought.
*   **Multi-modal Search**
    *   [12:51] But this is, I think, a
        very interesting problem.
    *   [12:55] And lots of
        interesting research is
        [12:56] going to continue
        happening in that area.
    *   [13:03] You can input images,
        text, audio, video.
*   **Example**
    *   [13:09] And we actually get really
        interesting results.
    *   [13:15] In this example, you
        see physics problem.
    *   [13:19] And then you give an image.
    *   [13:21] And then you continue
        with your text.
*   **Large Context**
    *   [13:24] And it's able to provide
        a pretty good response.
    *   [13:28] And you can try on AI
        Studio many of this.
    *   [13:33] And as I said, large context
        is really interesting.
*   **Experiment**
    *   [13:36] And if you want to try
        with videos, or with very
        [13:42] large amount of
        text, I think it's
        [13:45] very interesting to
        experiment with those.

**Needle in a Haystack Test**
=============================

*   **Test Description**
    *   [14:07] Let's drop a piece of sentence,
        or a piece of a video,
        [14:13] or a piece of an
        image, or something,
        [14:17] which is called the needle
        in a large amount of text
        [14:21] and see if the large language
        model is able to extract that.
*   **Relevance**
    *   [14:26] So if you especially want to
        do more research on that idea
        [14:30] about, OK, how do I
        build a search engine
        [14:32] using just large
        language models,
        [14:34] this test becomes
        really relevant for you.
*   **Results**
    *   [14:38] But also to be able to test
        all these large language
        [14:42] models as their input
        context increases,
        [14:46] this test is a very
        interesting test.

**LMSys Leaderboard**
=====================

*   **Ranking**
    *   [15:19] I think Gemini made it
        to number one in August.
    *   [15:23] Now, it's not.
    *   [15:25] Then it became number 2.
    *   [15:26] Then it changed again.
    *   [15:27] It's constantly changing.

**企業趨勢變化**
================

### 一、人工智慧 (AI) 的發展速度加快

*   **背景**: AI 在企業中的應用已經非常普遍。
*   **變化**: 企業對新產品的需求和採用的速度都在快速增加。

### 二、企業對 AI 的態度轉變

*   **過去**: 企業對 AI 的採用相當緩慢，通常需要數月甚至數年才能完成初步測試。
*   **現在**: 企業對新功能的需求和採用的速度都在快速增加，許多企業已經開始使用預先訓練好的基礎模型。

### 三、企業文化變化

*   **過去**: 開發 AI 應用程式需要大量的數據收集和清理。
*   **現在**: 企業可以利用現有的大型模型和語言模型，減少了數據收集和清理的時間。

### 四、企業對數據需求的變化

*   **過去**: 企業需要大量的數據才能進行 AI 應用的測試。
*   **現在**: 企業可以使用現有的大型模型和語言模型，減少了數據收集和清理的時間。

### 五、企業對 AI 的採用速度加快

*   **過去**: 企業需要數月甚至數年才能完成初步測試。
*   **現在**: 企業可以在幾天內開始使用新的功能。

**技術趨勢與文化變化**
=====================================

### 大型語言模型的變化

*   **從專業人士到開發者**
    *   現在任何開發者都可以使用大型語言模型建立 AI 應用程式
    *   這是以前不可能的
*   **文化轉變**
    *   公司正在改變其對 AI 的焦點，從專業人士轉向開發者

### 開發者的重要性

*   **數量上的差異**
    *   數據科學家與開發者的比例可能高達 100 倍
    *   這是為什麼我們看到的快速增長
*   **任何人都可以建立 AI 應用程式**
    *   現在任何人都可以使用大型語言模型建立 AI 應用程式

### 技術趨勢

*   **基礎模型的進步**
    *   基礎模型的進步速度如此之快，已經可以產生一個基礎模型和一個特定領域模型
    *   而且新的基礎模型通常會比之前的更好
*   **大型語言模型的應用**
    *   大型語言模型現在被用於各種不同的領域
    *   但是，仍然需要進一步的定制和調整

### 未來展望

*   **基礎模型的發展**
    *   將會看到更好的基礎模型出現
    *   這將會使得更多的人能夠使用大型語言模型建立 AI 應用程式
*   **定制和調整**
    *   將需要進一步的定制和調整，以適應不同的領域和用途

**趨勢與發展**
================

### 研究方向

*   **[22:18]**: 世界需要更多的研究在該領域。
*   **[22:30]**: 已經有許多人開始探索這個領域。

### 模型演進

#### 效率模型

*   **[22:50]**: 現在更注重於效率和稀疏模型。
*   **[23:00]**: 可以只執行 10% 的路徑，顯著降低延遲和成本。

### 多模態模型

*   **[23:36]**: 模型可以理解和產生多種模態的內容。
*   **[24:13]**: 選擇平台而不是模型變得重要。

### 平台選擇

*   **[24:17]**: 每隔幾周就會有新的模型出現。
*   **[24:39]**: 企業想要能夠試用多個模型。

### 對企業的影響

*   **[25:10]**: 能夠存取更多模型、自定義模型和選擇性變得重要。
*   **[25:32]**: 選擇性和靈活性在各層面都很重要。

**Vertex AI 架構**
================

### 成功模型和成功因素

*   **成功模型**: 
    *   建立在成功模型上的架構
    *   透過成功因素來改善生成式AI的表現
*   **成功因素**: 
    *   重要的關鍵因素
    *   用於提升生成式AI的效果

### 生產環境中的挑戰

*   **可靠性**: 
    *   在生產環境中，系統需要能夠返回結果的百分比達到98%或99.9999%
    *   這對於建立一個實際的生產算法或應用程式非常重要
*   **成本控制**: 
    *   API呼叫的成本正在趨近於零
    *   這是另一項很有趣的趨勢

### 硬體和芯片的改善

*   **GPU 的進步**: 
    *   GPU 的性能在持續增強
    *   這使得生成式AI的運算效率得到提高
*   **硬體成本的降低**: 
    *   因為API呼叫的成本趨近於零，使用開源模型可能比預期的還要貴

### 應用程式和搜索

*   **應用程式的延遲時間**: 
    *   延遲時間越小，越多的應用程式可以被執行
    *   這使得生成式AI在更多場景中有更大的可能性
*   **搜索功能**: 
    *   搜索功能與大型語言模型一起使用已經成為趨勢
    *   這使得系統能夠提供更好的結果

**大型語言模型的限制**
=====================================

### 限制一：過去訓練

*   大型語言模型通常是基於過去資料訓練的。
*   訓練時間可能只有兩週、兩個月或六個月。

### 限制二：假設和錯誤

*   **假設**：大型語言模型可能會產生假設，甚至在最佳模型中也會出現幾分之百的假設。
*   **錯誤**：這些假設可能是有意或無意的，並且很自信。

### 限制三：缺乏來源

*   大型語言模型可以進行推理和回答問題，但它們不能告訴你答案的來源。
*   這使得在某些應用中，例如健康、財務或客服等情況下，需要額外的搜索功能以驗證資訊。

### 趨勢

*   **趨勢一：結合搜索**

    *   在某些應用中，結合大型語言模型和搜索功能可以提高事實性。
    *   這是因為搜索功能可以提供額外的來源以驗證資訊。

*   **趨勢二：企業內部使用**

    *   企業正在越來越多地使用大型語言模型來提高員工生產力。
    *   這些工具可能會與其他應用相結合，例如客服或健康等。

### 結論

*   大型語言模型具有許多優點，但也有一些限制和趨勢需要被考慮。
*   在某些情況下，結合搜索功能可以提高事實性，而企業內部使用則可能會改善員工生產力。

**重要概念**
----------------

* **Vertex AI**: Google 的人工智慧平台
* **ModelBuilder**: 模型建造工具
* **Agent Builder**: 代理程式建造工具
* **GPU/TPU**: 計算硬體選擇
* **模型選擇與彈性**
* **開源模型**

**項目符號列表**
-----------------

### 模型選擇與彈性

* 提供多種模型選擇
* 可以自訂模型
* 支援 GPU/TPU 計算硬體
* 適合企業需求

### ModelBuilder 和 Agent Builder

* 模型建造工具
* 代理程式建造工具
* 透過這些工具可進行模型自訂和代理程式建造

### 開源模型

* 提供開源模型選擇
* 支援企業比較和評估不同模型的效能

### 其他相關內容

* **Chip 短缺**: 計算硬體短缺問題
* **模型訓練與調整**: 模型訓練和調整的重要性

**Distillation**
================

### 定義

*   **Distillation**: 將大型語言模型轉換為小型模型，能夠在特定用例中表現良好。

### 特點

*   小型模型
*   適合特定用例
*   能夠與大型模型相比之下，在某些方面表現更好

**Grounding**
=============

### 定義

*   **Grounding**: 將大型語言模型與搜尋功能結合，增強其知識的準確性。

### 特點

*   使用網絡搜尋或企業資料
*   增強模型的知識準確性

**Function Calling**
==================

### 定義

*   **Function Calling**: 將大型語言模型與外部功能結合，增強其能力。

### 特點

*   能夠呼叫外部功能以完成特定任務
*   需要能夠識別自己無法完成的任務，並呼叫適當的外部功能

**自然語言處理**
================

### **Fine-Tuning**

*   **Full Fine-Tuning**: 修改轉換器中的所有節點權重。
    *   需要大量的訓練資料。

### **Prompt Design**

*   提供 1-10 個範例，讓模型學習預期的輸出。
    *   需要大量的訓練資料。

### **Prompt-Tuning**

*   提供多個輸入，讓模型學習嵌入空間和嵌入向量。
    *   可以使用 1,000 個範例進行訓練。
    *   這種方法相對較少被使用。

### **Conventional Fine-Tuning**

*   使用預先訓練好的模型，更新所有或大部分的權重。
    *   需要大量的計算資源。

### **Distillation**

*   將知識從一個模型轉移到另一個模型中。
    *   尚未在此段落下相關內容。

**parameter-efficient fine-tuning**
=====================================

### 定義

* **LoRA (Low-Rank Adaptation)**: 一種參數效率的微調方法
* **IQ LoRA**: LoRA 的量化版本

### 優點

* 需要較少的計算資源，因為只更新特定部分的參數
* 可能需要較少的資料
* 在企業中非常流行

### 相關概念

* **B and A mattresses**: LoRA 中用於描述微調過程的概念
* **adapter**: LoRA 中用於儲存微調結果的部分

### 研究成果

* LoRA 和 IQ LoRA 的研究結果表明這種方法非常有效

### 其他相關資訊

* 微調後的模型可以減少延遲和成本
* 在企業中，微調是很重要的一步

**Teacher-Student Model**
==========================

### 概念介紹

*   **Teacher Model**: 一個大型模型，負責生成標籤。
*   **Student Model**: 一個小型模型，學習從 Teacher Model 中獲得的標籤。

### 教師學生模式的優點

*   **節省時間和成本**: 不需要人工標籤大量資料。
*   **提高效率**: Teacher Model 可以幫助生成標籤，減少人工工作量。

### 軟標籤和溫度控制

*   **軟標籤 (Soft Labels)**: Teacher Model 產生的標籤，不是硬性的。
*   **溫度控制 (Temperature)**: 控制 Teacher Model 的輸出分布，以達到想要的效果。

### 學習過程

1.  **Teacher Model**: 生成標籤。
2.  **Student Model**: 學習從 Teacher Model 中獲得的標籤，改善自己的預測能力。

### 相關概念

*   **類別分類 (Classification)**: 分類資料到不同類別中。
*   **相似度問題 (Similarity Problem)**: 找出兩個資料之間的相似度。

**深度學習**
================

### **Backpropagation**

*   能夠將輸出反饋給模型，以便調整權重。
*   可以用於硬預測，也可以用於軟預測。

### **Grounding**

*   為什麼需要grounding？
    *   因為訓練模型時，容易產生幻覺（hallucination）。
    *   需要提供正確的上下文給大型語言模型。
*   如何實現grounding？
    *   使用查詢算法（retrieval algorithm）。
    *   可以使用網路搜索來取得資料。

### **Factuality**

*   什麼是factuality？
    *   是指模型的輸出是否真實。
*   如何提高factuality？
    *   需要生成更好的模型，以便提高factuality。
    *   這需要額外的推理能力。

### **User Experience**

*   什麼是user experience？
    *   是指使用者對於模型輸出的滿意度。
*   如何改善user experience？
    *   需要提供權威性的結果。
    *   需要顯示資料來源。

**重要概念**
----------------

*   **Factuality**: 在下一段時間（6個月、12個月）內，許多大型語言模型生產商將更加注重事實性的發展。
*   **User Experience**: 使用者體驗取決於用途，許多客戶使用工具來檢視來源數量和相反的來源數量，並根據此進行答案的調整。
*   **Grounding**: 企業資料、第三方資料（如Moody's或Thomson Reuters）等都被用作基礎，以提高模型的準確性。
*   **Dynamic Retrieval**: 能夠智能地決定何時需要與搜尋引擎結合，何時不需要。

**項目符號列表**
-----------------

### 重要概念

*   **Factuality**
    *   在下一段時間內，許多大型語言模型生產商將更加注重事實性。
*   **User Experience**
    *   使用者體驗取決於用途。
    *   許多客戶使用工具來檢視來源數量和相反的來源數量，並根據此進行答案的調整。
*   **Grounding**
    *   企業資料、第三方資料等都被用作基礎，以提高模型的準確性。
*   **Dynamic Retrieval**
    *   能夠智能地決定何時需要與搜尋引擎結合，何時不需要。

### 相關內容

*   **Search Engine API Call Cost**
    *   搜尋引擎API呼叫成本幾乎沒有變化。
*   **LLM Cost Trend**
    *   大型語言模型的成本正在下降。

**大型語言模型的限制**
=====================================

### 大型語言模型的能力和限制

*   **能力**: 
    *   取得資訊
    *   對應用程式有幫助
*   **限制**:
    *   不能取行動
    *   不能改變健康紀錄或員工記錄
    *   不能購買產品或預定火車

### 解決方案

#### 定義函數

*   將程式功能分成多個步驟
*   每一步驟對應一個函數
*   例如: 旅行公司可以建立不同的函數來查詢航班時間、預訂機票和酒店

#### 函數呼叫

*   大型語言模型可以選擇要呼叫哪些函數
*   例如: 如果需要預定火車，則會呼叫相應的函數

#### 圖書館功能

*   可以建立一個圖書館來儲存各種函數
*   當需要時，可以從該圖書館中選擇和呼叫適合的函數

**挑戰與趨勢**
=====================================

### **功能呼叫延伸**

*   **挑戰**: 隨著更多的延伸被添加，需要更聰明地選擇合適的延伸來完成特定任務。
*   **好處**: 可以實現多種功能，例如提供結構化輸出、即時資訊檢索等。

### **評估工具**

*   **挑戰**: 隨著更多的功能被添加，需要評估工具來確保系統的正確性和效率。
*   **好處**: 提供評估工具可以幫助系統管理者評估系統的性能和準確性。

### **側面比較**

*   **挑戰**: 需要使用多個大型語言模型進行比較，以確保選擇最合適的模型。
*   **好處**: 可以提供更精確的結果，並且可以幫助系統管理者評估不同模型的性能和準確性。

### **人工智慧趨勢**

*   **挑戰**: 人工智慧短缺，需要使用大型語言模型來取代人工評估。
*   **好處**: 可以提供更快速、更精確的結果，並且可以幫助系統管理者評估不同模型的性能和準確性。

**重要概念**
================

* **AI**: 人工智慧
* **趨勢**: AI 的發展速度和規模

**筆記**
--------

### 1. 公開公告

* [60:46] 這些都是公開的公告。
* 公司們看到相似的趨勢。

### 2. AI 的成長

* [60:54] 每年在企業世界中的 API 成長率達到 36 倍。
* [61:21] 通常需要 5-10 年才能達到這樣的成長。
* 這是短短半年的成就。

### 3. 未來展望

* [61:43] AI 的趨勢將繼續下去。
* 將會有更多的創新和發展。

### 4. 建議

* [62:02] 學習 AI 和其他科學領域的基礎知識。
* 加入創意和藝術的元素，培養思維能力。
* 進一步了解程式設計的變化和未來趨勢。

---
## 參考資料
- 原始影片：[CS 194/294-196 (LLM Agents) - Lecture 4, Burak Gokturk](https://youtube.com/watch?v=Sy1psHS3w3I)
